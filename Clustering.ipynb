{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7c40d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Dec 24 18:35:10 2021\n",
    "@author: Arya\n",
    "\"\"\"\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import math\n",
    "import glob\n",
    "import numpy\n",
    "#import pandas\n",
    "import string\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from math import log\n",
    "from sklearn import metrics\n",
    "from functools import reduce\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import recall_score\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f2e97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "corpus = \"\"\"\n",
    "Simple example with Cats and Mouse\n",
    "Another simple example with dogs and cats\n",
    "Another simple example with mouse and cheese\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70817e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simple', 'example', 'with', 'cats', 'and', 'mouse']\n",
      "['another', 'simple', 'example', 'with', 'dogs', 'and', 'cats']\n",
      "['another', 'simple', 'example', 'with', 'mouse', 'and', 'cheese']\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "l_A = corpus[0].lower().split()\n",
    "l_B = corpus[1].lower().split()\n",
    "l_C = corpus[2].lower().split()\n",
    "\n",
    "print(l_A)\n",
    "print(l_B)\n",
    "print(l_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1c0387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cheese', 'and', 'another', 'cats', 'dogs', 'mouse', 'simple', 'example', 'with'}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "word_set = set(l_A).union(set(l_B)).union(set(l_C))\n",
    "print(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b2b950d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cheese</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>example</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cheese  and  another  cats  dogs  mouse  simple  example  with\n",
       "0       0    1        0     1     0      1       1        1     1\n",
       "1       0    1        1     1     1      0       1        1     1\n",
       "2       1    1        1     0     0      1       1        1     1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "word_dict_A = dict.fromkeys(word_set, 0)\n",
    "word_dict_B = dict.fromkeys(word_set, 0)\n",
    "word_dict_C = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in l_A:\n",
    "    word_dict_A[word] += 1\n",
    "\n",
    "for word in l_B:\n",
    "    word_dict_B[word] += 1\n",
    "    \n",
    "for word in l_C:\n",
    "    word_dict_C[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict_A, word_dict_B, word_dict_C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50b47f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 tf - term frequency\n",
    "\n",
    "def compute_tf(word_dict, l):\n",
    "    tf = {}\n",
    "    sum_nk = len(l)\n",
    "    for word, count in word_dict.items():\n",
    "        tf[word] = count/sum_nk\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e07f9905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cheese': 0.0, 'and': 0.16666666666666666, 'another': 0.0, 'cats': 0.16666666666666666, 'dogs': 0.0, 'mouse': 0.16666666666666666, 'simple': 0.16666666666666666, 'example': 0.16666666666666666, 'with': 0.16666666666666666}\n",
      "{'cheese': 0.0, 'and': 0.14285714285714285, 'another': 0.14285714285714285, 'cats': 0.14285714285714285, 'dogs': 0.14285714285714285, 'mouse': 0.0, 'simple': 0.14285714285714285, 'example': 0.14285714285714285, 'with': 0.14285714285714285}\n",
      "{'cheese': 0.14285714285714285, 'and': 0.14285714285714285, 'another': 0.14285714285714285, 'cats': 0.0, 'dogs': 0.0, 'mouse': 0.14285714285714285, 'simple': 0.14285714285714285, 'example': 0.14285714285714285, 'with': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "tf_A = compute_tf(word_dict_A, l_A)\n",
    "tf_B = compute_tf(word_dict_B, l_B)\n",
    "tf_C = compute_tf(word_dict_C, l_C)\n",
    "print(tf_A)\n",
    "print(tf_B)\n",
    "print(tf_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5cab2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 idf - inverse document frequency\n",
    "\n",
    "def compute_idf(strings_list):\n",
    "    n = len(strings_list)\n",
    "    idf = dict.fromkeys(strings_list[0].keys(), 0)\n",
    "    for l in strings_list:\n",
    "        for word, count in l.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, v in idf.items():\n",
    "        idf[word] = log(n / float(v))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2cd9f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cheese</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>example</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cheese  and   another      cats      dogs     mouse  simple  example  \\\n",
       "0  1.098612  0.0  0.405465  0.405465  1.098612  0.405465     0.0      0.0   \n",
       "\n",
       "   with  \n",
       "0   0.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = compute_idf([word_dict_A, word_dict_B, word_dict_C])\n",
    "# print(idf)\n",
    "pd.DataFrame([idf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e48b5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 tf-idf\n",
    "\n",
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = dict.fromkeys(tf.keys(), 0)\n",
    "    for word, v in tf.items():\n",
    "        tf_idf[word] = v * idf[word]\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "292f43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_A = compute_tf_idf(tf_A, idf)\n",
    "tf_idf_B = compute_tf_idf(tf_B, idf)\n",
    "tf_idf_C = compute_tf_idf(tf_C, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90637e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cheese</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>mouse</th>\n",
       "      <th>simple</th>\n",
       "      <th>example</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cheese  and   another      cats      dogs     mouse  simple  example  \\\n",
       "0  0.000000  0.0  0.000000  0.067578  0.000000  0.067578     0.0      0.0   \n",
       "1  0.000000  0.0  0.057924  0.057924  0.156945  0.000000     0.0      0.0   \n",
       "2  0.156945  0.0  0.057924  0.000000  0.000000  0.057924     0.0      0.0   \n",
       "\n",
       "   with  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tf_idf_A, tf_idf_B, tf_idf_C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "991b4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3a6e9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_text = \"\"\"\n",
    "# Google and Facebook are strangling the free press to death. Democracy is the loser\n",
    "# Your 60-second guide to security stuff Google touted today at Next '18\n",
    "# A Guide to Using Android Without Selling Your Soul to Google\n",
    "# Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "# Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "# Android is better than IOS\n",
    "# In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "# is a numerical statistic that is intended to reflect\n",
    "# how important a word is to a document in a collection or corpus.\n",
    "# It is often used as a weighting factor in searches of information retrieval\n",
    "# text mining, and user modeling. The tf-idf value increases proportionally\n",
    "# to the number of times a word appears in the document\n",
    "# and is offset by the frequency of the word in the corpus\n",
    "# \"\"\".split(\"\\n\")[1:-1]\n",
    "\n",
    "#1\n",
    "labels = [ \"grain\", \"earn\", \"acq\", \"ship\", \"money-fx\", \"trade\",\"crude\",\"interest\"]\n",
    "y_true = []\n",
    "texts = []\n",
    "openig = open('news.csv', 'r')\n",
    "reading = csv.reader(openig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8428426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep():\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for line in reading:\n",
    "    # for field in line:\n",
    "        get_token = nltk.word_tokenize(line[1])\n",
    "        stop_words_removed = [w for w in get_token if not w.lower() in stop_words]\n",
    "        stop_words_removed = []\n",
    "\n",
    "        for w in get_token:\n",
    "            if w not in stop_words_removed:\n",
    "                stop_words_removed.append(w)\n",
    "        # print(get_token)\n",
    "        words = [word for word in stop_words_removed if word.isalpha()]\n",
    "\n",
    "        porter = PorterStemmer()\n",
    "        stemmed = [porter.stem(word) for word in words]\n",
    "\n",
    "        y_true.append(labels.index(line[2]))\n",
    "\n",
    "        string_tokens=' '.join([str(elem) for elem in stemmed])\n",
    "        texts.append(string_tokens)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a45e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textReader(fname):\n",
    "    doc=open(fname,'rb')\n",
    "    document = ' '.join(line.decode('utf-8').strip() for line in doc.readlines())\n",
    "    return document\n",
    "\n",
    "documents=[]\n",
    "for files in glob.glob(\"5501_files/*.txt\"):\n",
    "     documents.append(textReader(files))\n",
    "          \n",
    "nltk_tokenizer=RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for index,document in enumerate(documents):\n",
    "    documents[index]= nltk_tokenizer.tokenize(document)\n",
    "    \n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "for index,document in enumerate(documents):\n",
    "    documents[index]=[w for w in document if w not in stop_words ]\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "all_words=[]\n",
    "\n",
    "# print (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0a26add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3bae9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing, max_features=3000)\n",
    "tfidf = tfidf_vectorizer.fit_transform(prep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0aa0fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7fd6f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_for_predicting = texts\n",
    "y_pred = kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0054098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def purity_score_1(y_true, y_pred):\n",
    "#     \"\"\"Purity score\n",
    "#         Args:\n",
    "#             y_true(np.ndarray): n*1 matrix Ground truth labels\n",
    "#             y_pred(np.ndarray): n*1 matrix Predicted clusters\n",
    "\n",
    "#         Returns:\n",
    "#             float: Purity score\n",
    "#     \"\"\"\n",
    "#     # matrix which will hold the majority-voted labels\n",
    "#     y_voted_labels = np.zeros(y_true.shape)\n",
    "#     # Ordering labels\n",
    "#     ## Labels might be missing e.g with set like 0,2 where 1 is missing\n",
    "#     ## First find the unique labels, then map the labels to an ordered set\n",
    "#     ## 0,2 should become 0,1\n",
    "#     labels = np.unique(y_true)\n",
    "#     ordered_labels = np.arange(labels.shape[0])\n",
    "#     for k in range(labels.shape[0]):\n",
    "#         y_true[y_true==labels[k]] = ordered_labels[k]\n",
    "#     # Update unique labels\n",
    "#     labels = np.unique(y_true)\n",
    "#     # We set the number of bins to be n_classes+2 so that \n",
    "#     # we count the actual occurence of classes between two consecutive bins\n",
    "#     # the bigger being excluded [bin_i, bin_i+1[\n",
    "#     bins = np.concatenate((labels, [np.max(labels)+1]), axis=0)\n",
    "\n",
    "#     for cluster in np.unique(y_pred):\n",
    "#         hist, _ = np.histogram(y_true[y_pred==cluster], bins=bins)\n",
    "#         # Find the most present label in the cluster\n",
    "#         winner = np.argmax(hist)\n",
    "#         y_voted_labels[y_pred==cluster] = winner\n",
    "\n",
    "#     return accuracy_score(y_true, y_voted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d945a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # print(contingency_matrix)\n",
    "    return numpy.sum(numpy.amax(contingency_matrix, axis=0)) / numpy.sum(contingency_matrix) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2eaacaac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity Score is:  0.77059\n"
     ]
    }
   ],
   "source": [
    "purity_score(y_true, y_pred)\n",
    "c_purity_score = round(purity_score(y_true, y_pred), 5)\n",
    "print(\"purity Score is: \", c_purity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "29fc4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI Score is:  0.27014\n"
     ]
    }
   ],
   "source": [
    "adjusted_rand_score(y_true, y_pred)\n",
    "c_adjusted_rand_score = round(adjusted_rand_score(y_true, y_pred), 5)\n",
    "print(\"RI Score is: \", c_adjusted_rand_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "53e07283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Mutual Information Score is:  0.43557\n"
     ]
    }
   ],
   "source": [
    "normalized_mutual_info_score(y_true, y_pred)\n",
    "c_normalized_mutual_info_score = round(normalized_mutual_info_score(y_true, y_pred), 5)\n",
    "print(\"Normalized Mutual Information Score is: \", c_normalized_mutual_info_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "605c034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score is:  0.79633\n"
     ]
    }
   ],
   "source": [
    "prs = precision_score(y_true, y_pred, average='weighted')\n",
    "c_prs = round(precision_score(y_true, y_pred, average='weighted'), 5)\n",
    "print(\"Precision Score is: \", c_prs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cf43e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score is:  0.39211\n"
     ]
    }
   ],
   "source": [
    "rcs = recall_score(y_true, y_pred, average='weighted')\n",
    "c_rcs = round(recall_score(y_true, y_pred, average='weighted'), 5)\n",
    "print(\"Recall Score is: \", c_rcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c1a12a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score(1) is:  0.52548\n"
     ]
    }
   ],
   "source": [
    "f1 = (2)*(prs * rcs)/(prs + rcs)\n",
    "c_f1 = round(f1, 5)\n",
    "print(\"F1 Score(1) is: \", c_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c92154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,   34,    7,    0,    0,    0],\n",
       "       [ 229,  681,   57,   50,  234,  455,  442,  692],\n",
       "       [   2,    0, 1282,  165,  128,   19,    0,    0],\n",
       "       [   0,    0,   11,   87,   10,    0,    0,    0],\n",
       "       [   0,    0,    1,  114,  107,    0,    0,    0],\n",
       "       [   0,    0,    0,  224,   26,    0,    0,    0],\n",
       "       [   0,    0,   15,  188,   49,    1,    0,    0],\n",
       "       [   0,    0,    1,   40,  150,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7bd2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([y_true,  y_pred])\n",
    "# confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "30588ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_link_agglomerative = AgglomerativeClustering(n_clusters=8, linkage='average').fit(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "613e13db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Link Purity Score is:  0.69787\n",
      "Average Link RI Score is:  0.33946\n",
      "Average Link Normalized Mutual Information Score is:  0.37165\n",
      "Average Link F1 Score(1) is:  0.12847\n"
     ]
    }
   ],
   "source": [
    "purity_score(y_true, average_link_agglomerative.labels_)\n",
    "c_purity_score = round(purity_score(y_true, average_link_agglomerative.labels_), 5)\n",
    "print(\"Average Link Purity Score is: \", c_purity_score)\n",
    "\n",
    "adjusted_rand_score(y_true, average_link_agglomerative.labels_)\n",
    "c_adjusted_rand_score = round(adjusted_rand_score(y_true, average_link_agglomerative.labels_), 5)\n",
    "print(\"Average Link RI Score is: \", c_adjusted_rand_score)\n",
    "\n",
    "normalized_mutual_info_score(y_true,average_link_agglomerative.labels_)\n",
    "c_normalized_mutual_info_score = round(normalized_mutual_info_score(y_true,average_link_agglomerative.labels_), 5)\n",
    "print(\"Average Link Normalized Mutual Information Score is: \", c_normalized_mutual_info_score)\n",
    "\n",
    "f1_score(y_true, average_link_agglomerative.labels_, average='macro')\n",
    "print(\"Average Link F1 Score(1) is: \", round(f1_score(y_true, average_link_agglomerative.labels_, average='macro'),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c095f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_link_agglomerative = AgglomerativeClustering(n_clusters=8, linkage='complete').fit(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "234e7193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Link Purity Score is:  0.64025\n",
      "Complete Link RI Score is:  0.21961\n",
      "Complete Link Normalized Mutual Information Score is:  0.23629\n",
      "Complete Link F1 Score(1) is:  0.06759\n"
     ]
    }
   ],
   "source": [
    "purity_score(y_true, complete_link_agglomerative.labels_)\n",
    "c_purity_score = round(purity_score(y_true, complete_link_agglomerative.labels_), 5)\n",
    "print(\"Complete Link Purity Score is: \", c_purity_score)\n",
    "\n",
    "adjusted_rand_score(y_true, complete_link_agglomerative.labels_)\n",
    "c_adjusted_rand_score = round(adjusted_rand_score(y_true, complete_link_agglomerative.labels_), 5)\n",
    "print(\"Complete Link RI Score is: \", c_adjusted_rand_score)\n",
    "\n",
    "normalized_mutual_info_score(y_true,complete_link_agglomerative.labels_)\n",
    "c_normalized_mutual_info_score = round(normalized_mutual_info_score(y_true,complete_link_agglomerative.labels_), 5)\n",
    "print(\"Complete Link Normalized Mutual Information Score is: \", c_normalized_mutual_info_score)\n",
    "\n",
    "f1_score(y_true, complete_link_agglomerative.labels_, average='macro')\n",
    "print(\"Complete Link F1 Score(1) is: \", round(f1_score(y_true, complete_link_agglomerative.labels_, average='macro'),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7bc9ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_link_agglomerative = AgglomerativeClustering(n_clusters=8, linkage='single').fit(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7184a1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Link Purity Score is:  0.51736\n",
      "Single Link RI Score is:  0.00195\n",
      "Single Link Normalized Mutual Information Score is:  0.00517\n",
      "Single Link F1 Score(1) is:  0.00185\n"
     ]
    }
   ],
   "source": [
    "purity_score(y_true, single_link_agglomerative.labels_)\n",
    "c_purity_score = round(purity_score(y_true, single_link_agglomerative.labels_), 5)\n",
    "print(\"Single Link Purity Score is: \", c_purity_score)\n",
    "\n",
    "adjusted_rand_score(y_true, single_link_agglomerative.labels_)\n",
    "c_adjusted_rand_score = round(adjusted_rand_score(y_true, single_link_agglomerative.labels_), 5)\n",
    "print(\"Single Link RI Score is: \", c_adjusted_rand_score)\n",
    "\n",
    "normalized_mutual_info_score(y_true,single_link_agglomerative.labels_)\n",
    "c_normalized_mutual_info_score = round(normalized_mutual_info_score(y_true,single_link_agglomerative.labels_), 5)\n",
    "print(\"Single Link Normalized Mutual Information Score is: \", c_normalized_mutual_info_score)\n",
    "\n",
    "f1_score(y_true, single_link_agglomerative.labels_, average='macro')\n",
    "print(\"Single Link F1 Score(1) is: \", round(f1_score(y_true, single_link_agglomerative.labels_, average='macro'),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ce902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5d736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd5e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482bf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b530b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fcc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5bc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd3c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad6bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789d04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c9dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
